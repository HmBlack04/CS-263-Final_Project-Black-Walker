<!DOCTYPE html>
<html>
    <head>
        <link rel="stylesheet" href="general.css">
        <link rel="stylesheet" href="homepage_style.css">
        <link rel="stylesheet" href="background_style.css">
    </head>
    <body>
        <header>
            <h1>Our Website title</h1>
        </header>
        <nav class="navbar">
            <a class="navbutton" href="homepage.html"><strong>Home</strong></a></li>
            <a class="navbutton" href="background.html"><strong>Background</strong></a></li>
            <a class="navbutton" href="issues.html"><strong>Issues</strong></a></li>
            <a class="navbutton" href="ethical_lenses.html"><strong>The Ethics</strong></a></li>
            <a class="navbutton" href="solutions.html"><strong>Solutions</strong></a></li>
            <a class="navbutton" href="about.html"><strong>About</strong></a></li>
        </nav>
        <h2>Background</h2>
        <p>Predictive policing is a term used to describe complex algorithms created by private companies and used by police agencies in order to predict when or where crimes will happen based on past data. These algorithms often use machine learning (a field of artificial intelligence) in order to become more accurate. </p>
        <h3>Machine Learning</h3>
        <p>Machine learning is essentially an algorithm training itself to become more accurate in its predictions. This initially sounds like some kind of sentient being learning from its mistakes, but in reality, machine learning can be simplified down to just an algorithm for predicting data and then adjusting based on the results. One example of this kind of algorithm is a perceptron. A perceptron essentially assigns weights to each datapoint that is inputted, sums them up, and then makes a prediction. If the prediction is correct, the weights remain unchanged, and if it is false, the weights are adjusted based on a formula that takes in the difference between the prediction and the correct answer. These kinds of algorithms only begin to approach anything sensible when they are run through thousands of tests and adjustments on training data. When used in the policing world, there are a few different common applications.Machine learning...</p>
        <h4>Uses</h4>
        <p>Location-based algorithms take in existing crime data to predict what areas and times are at a higher risk for crime. One example of a location-based algorithm is RTM, or risk-terrain modeling. Tested in New Jersey but never actually used by a police force, RTM takes in locational/temporal data that includes not only past criminal activity, but also factors such as weather, sporting events, school calendars, locations of gas stations / restaurants / bars / etc, and more (Carleton). All of this data is entered into the algorithm in order to produce a map signifying the risk of crime in each area.
        </p>
        <p>Person-based algorithms take in the existing crime data of individual citizens to predict who is most likely to commit a crime. One example of a person-based algorithm is SSL, or the Strategic Subject List. Used by the Chicago Police Department and then discontinued, this algorithm takes in eight data points about individual citizens, all of which involve previous criminal activity, to assign a risk score to each citizen (Chicago Data Portal).
        </p>
        <p>Pattern recognition algorithms take in existing crime data and try to find patterns and make connections between them in order to find the source, i.e. the criminal or group of criminals responsible. One example of a pattern recognition algorithm is Patternizr, an algorithm used by the NYPD and still in use today. Patternizr is trained on 10 years of crime data with patterns that have already been identified, while removing data points such as gender and race (Holak).</p>
    </body>
</html>