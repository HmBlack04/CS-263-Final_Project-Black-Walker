<!DOCTYPE html>
<html>
    <head>
        <link rel="stylesheet" href="general.css">
        <link rel="stylesheet" href="homepage_style.css">
        <link rel="stylesheet" href="background_style.css">
    </head>

    <body>
        <header role="Website Title">
            <h1>Our Website title</h1>
        </header>
        <nav class="navbar">
            <a class="navbutton" href="homepage.html"><strong>Home</strong></a></li>
            <a class="navbutton" href="background.html"><strong>Background</strong></a></li>
            <a class="navbutton" href="issues.html"><strong>Issues</strong></a></li>
            <a class="navbutton" href="ethical_lenses.html"><strong>The Ethics</strong></a></li>
            <a class="navbutton" href="solutions.html"><strong>Solutions</strong></a></li>
            <a class="navbutton" href="about.html"><strong>About</strong></a></li>
        </nav>
        <h2>Issues</h2>
        <h3>Bias</h3>
        <p>While the concept of using algorithms in policing may seem unbiased because algorithms are just running numbers, the unfortunate truth is that these algorithms often only compound biases. This is because algorithms learn from previous crime data, and this previous crime data is already infected with countless biased outcomes. In other words, the algorithms are trained not necessarily to come up with the most correct answer, but instead to most accurately recreate past answers. Since these past answers often involve bias, this bias is trained into the algorithm, even if factors such as race and gender are removed from the dataset.
        </p>
        <h4>The Black Box</h4>
        <p>A major problem with using machine learning algorithms in policing is the lack of transparency between the creators of the software, the police agencies, and the public. Sometimes the software is privatized and the creators can’t even tell the police agencies what information is being used for the software to make decisions. Even if the police agencies are told, they often don’t have the computer science expertise to truly understand what the algorithms are doing. Additionally, the public is usually not informed of what variables are being considered by the algorithm, even if the police agencies are. This creates a “black box” around the software and makes it difficult to understand why it comes to the conclusions it does.
        </p>
        <h5>Costliness</h5>
        <p>These algorithms are usually very expensive to purchase, with varying but often low levels of effectiveness in practice. This brings up the question of whether the resources being allocated in this area could be better distributed in order to truly enact a positive change.</p>
    </body>

</html>